{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0bdTBCBjz8T",
    "outputId": "b3246f64-2816-4449-e1af-2bfcf3f28a7a"
   },
   "source": [
    "## Cuda project\n",
    "\n",
    "### **1.1 Introduction and purpose**\n",
    "\n",
    "This project demonstrates an **extended GPU-based application** that leverages CUDA, cuBLAS, and cuDNN to illustrate multiple GPU-accelerated tasks. Specifically, the code covers:\n",
    "\n",
    "1. **Basic vector operations** on the GPU (array filling, array addition, and elementwise operations like ReLU).\n",
    "2. **Dot product** and **matrix-vector multiply** using cuBLAS, showcasing linear algebra routines on the GPU.\n",
    "3. **Simple multi-layer perceptron (MLP) training** with backpropagation, illustrating how to compute gradients on GPU and apply basic gradient updates.\n",
    "4. **cuDNN features** such as Convolution, Activation (ReLU), Pooling, and Softmax, highlighting how higher-level GPU-accelerated library functions can be combined.\n",
    "5. **NPP (NVIDIA Performance Primitives) Stub** for image rotation. Although it is only a placeholder, it indicates how NPP might be used for image-processing tasks on the GPU.\n",
    "\n",
    "Beyond simply demonstrating how to call these libraries, the code also includes an **example training loop** for a small neural network, proving that these GPU kernels and library routines can be part of a real training pipeline. \n",
    "\n",
    "### **1.2 Basic vector operations**\n",
    "\n",
    "#### **1.2.1 Array fill**\n",
    "One of the simplest GPU tasks is filling an array on the device with a constant value. This involves:\n",
    "- Defining a CUDA kernel (e.g., `fillArrayKernel`) that assigns `value` to each element of the array.\n",
    "- Launching this kernel with a grid-stride loop or a conventional block/thread approach.\n",
    "- Ensuring we handle synchronization correctly (e.g., `cudaDeviceSynchronize()`).\n",
    "\n",
    "By running this **fill** on the GPU, we can quickly initialize large arrays without transferring repeated data from the CPU.\n",
    "\n",
    "#### **1.2.2 Array addition**\n",
    "We implement elementwise array addition—another basic building block for larger computations. The code uses a kernel (e.g., `addArraysKernel`) that does `c[i] = a[i] + b[i]`. This is fundamental when building more complex arithmetic (such as adding gradients, adding partial results, etc.).\n",
    "\n",
    "#### **1.2.3 ReLU and reLU backward**\n",
    "Rectified Linear Unit (ReLU) is a very common activation function in neural networks.  \n",
    "- **Forward ReLU** sets each value to `max(0, x)`.  \n",
    "- **Backward ReLU** sets the gradient to zero wherever `x` is not positive.  \n",
    "\n",
    "These are implemented as simple CUDA kernels scanning the array and applying the function. While trivial, they highlight how easily parallel elementwise computations can be done in CUDA.\n",
    "\n",
    "### **1.3 cuBLAS: Linear Algebra on the GPU**\n",
    "\n",
    "#### **1.3.1 Dot product**\n",
    "A dot product (or scalar product) is a fundamental vector operation. We use **cuBLAS**—NVIDIA’s BLAS implementation on GPUs—to call `cublasSdot`, which sums up elementwise products of two vectors. By delegating to cuBLAS instead of writing our own kernel, we ensure we use well-optimized library routines.\n",
    "\n",
    "#### **1.3.2 Matrix-Vector multiply (SGEMV)**\n",
    "Similarly, we show **matrix-vector multiplication** using `cublasSgemv`. This multiplies a 2D matrix A by a 1D vector x, resulting in an output vector y. Typically used in neural network layers, matrix-vector multiplication is accelerated with specialized GPU routines that make it highly efficient for large-scale linear algebra.\n",
    "\n",
    "#### **1.3.3 Matrix-Matrix multiply (SGEMM)**\n",
    "While not explicitly singled out in this bullet, the code’s feed-forward layer uses `cublasSgemm` for matrix multiplication (W × X). This is an essential operation in neural network training. By calling `cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, ...)`, we multiply a matrix W by vector X (treated as a matrix with one column) to get an output vector.\n",
    "\n",
    "### **1.4 Simple multi-layer perceptron (MLP) training**\n",
    "\n",
    "#### **1.4.1 overview of the MLP**\n",
    "An MLP is a feed-forward neural network with one or more hidden layers. Our example uses:\n",
    "- An **input layer** of dimension `inputSize`.\n",
    "- A **hidden layer** of dimension `hiddenSize`, with ReLU activation.\n",
    "- An **output layer** of dimension `outputSize`.\n",
    "\n",
    "We store the weights as two matrices (`W1` for the hidden layer, `W2` for the output layer) and the biases as `b1` and `b2`.\n",
    "\n",
    "#### **1.4.2 Forward Pass**\n",
    "1. We compute `h1 = ReLU(W1 × x + b1)`.\n",
    "2. Then we compute `h2 = W2 × h1 + b2`.\n",
    "3. We interpret `h2` as the final output.\n",
    "\n",
    "#### **1.4.3 MSE Loss Computation**\n",
    "We define our loss (Mean Squared Error, MSE) as \n",
    "$$\n",
    "L = \\frac{1}{2}\\sum_i \\bigl( h2[i] - yGT[i] \\bigr)^2.\n",
    "$$\n",
    "- We first copy `h2` into a buffer.\n",
    "- Subtract `yGT` from it.\n",
    "- Square each element times 0.5 in a kernel.\n",
    "- Optionally sum it up on the CPU to get a scalar value to print out each iteration.\n",
    "\n",
    "#### **1.4.4 Backpropagation**\n",
    "We compute:\n",
    "1. $\\text{gradOut2} = h2 - yGT$  \n",
    "2. $\\text{gradW2}, \\text{gradB2}, \\text{gradH1}$ by using the formula for a fully connected layer:\n",
    "   - $\\text{gradW2} = \\text{gradOut2} \\times (h1)^T$\n",
    "   - $\\text{gradB2} = \\text{gradOut2}$\n",
    "   - $\\text{gradH1} = (W2)^T \\times \\text{gradOut2}$\n",
    "\n",
    "3. We pass `gradH1` through the **ReLU backward** kernel to zero out any gradient components where `h1` was non-positive.\n",
    "4. We similarly backprop into `W1` and `b1` with `gradH1` and `x`.\n",
    "\n",
    "#### **1.4.5 Gradient Update**\n",
    "Crucially, to ensure the MSE does not remain zero or constant, we do a gradient descent step:\n",
    "\n",
    "$$\n",
    "W \\leftarrow W - \\eta \\cdot \\text{gradW}, \\quad b \\leftarrow b - \\eta \\cdot \\text{gradB}.\n",
    "$$\n",
    "\n",
    "Here, $\\eta$ is the learning rate. By default, the example uses `0.01f`. The code uses `cublasSaxpy` to apply the gradient with a negative scale, i.e.:\n",
    "$$\n",
    "\\text{Saxpy}(\\text{negLR}, \\text{gradW}, W).\n",
    "$$\n",
    "\n",
    "#### **1.4.6 Iterations**\n",
    "We iterate forward/backward passes multiple times (e.g. `iterations = 5`). This demonstrates how the network’s weights change, typically causing the MSE to decrease (unless random initial conditions or a particular setup hamper training).\n",
    "\n",
    "### **1.5 cuDNN: High-Level GPU primitives**\n",
    "\n",
    "#### **1.5.1 Convolution**\n",
    "We set up a toy convolution example with:\n",
    "- An input descriptor for 1 × 1 × 28 × 28 data.\n",
    "- A filter descriptor of 1 × 1 × 5 × 5.\n",
    "- No padding and stride of 1.\n",
    "\n",
    "We choose `CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM` for the forward pass. This step shows how one might implement a typical “conv layer” in a CNN.\n",
    "\n",
    "#### **1.5.2 Activation (ReLU)**\n",
    "Using cuDNN’s activation descriptor, we configure a ReLU activation with `CUDNN_ACTIVATION_RELU`. This encapsulates the same concept as our custom ReLU kernel, but managed by the library.\n",
    "\n",
    "#### **1.5.3 Pooling**\n",
    "We demonstrate a **max-pool** operation with a 2 × 2 kernel and a stride of 2 on a 6 × 6 input, producing a 3 × 3 output. This is typical in CNN downsampling.\n",
    "\n",
    "#### **1.5.4 Softmax**\n",
    "Finally, we show how to apply a softmax transformation on a 5-element vector. This is common in classification tasks (turning a vector of logits into probabilities). cuDNN offers multiple modes like `CUDNN_SOFTMAX_FAST` or `CUDNN_SOFTMAX_ACCURATE`.\n",
    "\n",
    "### **1.6 NPP Stub: Image rotation**\n",
    "\n",
    "The code includes a placeholder function, `nppImageRotationExample()`, which prints a message indicating how one might rotate an image using NPP. While the example does not implement the full rotation, it demonstrates how to structure a call to NPP for image manipulation if needed. NPP is a collection of image- and signal-processing primitives optimized for NVIDIA GPUs.\n",
    "\n",
    "### **1.7 Build instructions**\n",
    "\n",
    "The code references a command:\n",
    "\n",
    "```\n",
    "nvcc code_cuda.cu -o code_cuda -lcudart -lcublas -lcudnn\n",
    "```\n",
    "\n",
    "This compiles and links against the **CUDA Runtime** (`-lcudart`), **cuBLAS** (`-lcublas`), and **cuDNN** (`-lcudnn`). Ensure you have installed CUDA, cuBLAS, and cuDNN:\n",
    "\n",
    "- **CUDA Toolkit** version ~11 or 12 (includes `nvcc`).\n",
    "- **cuDNN** library that matches your CUDA version.\n",
    "- **libnpp** if you want to do actual image operations.\n",
    "\n",
    "With these libraries in place, compilation should succeed.\n",
    "\n",
    "### **1.8 Lessons learned**\n",
    "\n",
    "1. **GPU memory management**: We see the repeated pattern of `cudaMalloc`/`cudaFree`, which underscores the importance of carefully allocating and releasing device memory.\n",
    "2. **Performance**: Using library routines (cuBLAS, cuDNN) typically outperforms custom kernels, saving development time and ensuring robust performance.\n",
    "3. **Numerical stability**: Repeated floating-point updates in gradient descent can lead to very small or large values. Tuning the learning rate or initialization can help.\n",
    "4. **Debugging**: Without sign flipping or with direct usage of `cublasScopy` and `cublasSaxpy`, we avoid tricky indexing or sign mistakes that yield zero MSE.\n",
    "\n",
    "### **1.9 Conclusion**\n",
    "\n",
    "In summary, the code demonstrates a variety of **GPU-accelerated operations** that would be fundamental in real-world deep learning or HPC pipelines. By combining custom CUDA kernels for small tasks with high-performance libraries like cuBLAS and cuDNN, we can achieve efficient training loops, advanced image processing, and more. The modular design (separable forward and backward passes, plus separate library calls) further showcases how these building blocks might be integrated into larger projects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0bdTBCBjz8T",
    "outputId": "b3246f64-2816-4449-e1af-2bfcf3f28a7a"
   },
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKlDvgzGkQhC",
    "outputId": "1fbfabe9-3980-40ed-a9f9-e79f7b9b327c"
   },
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rblKOP42kW_S",
    "outputId": "96174284-05fb-440d-bd98-43365fb51194"
   },
   "outputs": [],
   "source": [
    "!cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rmbt3lNqlf9t",
    "outputId": "301bee34-576d-4a6e-90ad-fcf388f8c67f"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install -y libnpp-dev-11-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MI4LSD4HkX-5",
    "outputId": "af84069a-4657-4c56-a171-8e7c9a994637"
   },
   "outputs": [],
   "source": [
    "%%writefile code_cuda.cu\n",
    "/***************************************************\n",
    " * code_cuda.cu\n",
    " *\n",
    " * Extended example GPU-based project demonstrating:\n",
    " *   1. Basic vector ops (addition, fill, ReLU, etc.)\n",
    " *   2. Dot product and mat-vector multiply via cuBLAS\n",
    " *   3. Simple feed-forward MLP training (2-layer) with\n",
    " *      nonzero MSE and actual gradient update\n",
    " *   4. Simple cuDNN convolution, activation, pooling, softmax\n",
    " *   5. (Stub) NPP image rotation\n",
    " *\n",
    " * Build (example):\n",
    " *   nvcc code_cuda.cu -o code_cuda -lcudart -lcublas -lcudnn\n",
    " **************************************************/\n",
    "\n",
    "#include <iostream>\n",
    "#include <iomanip>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <cstdio>\n",
    "#include <cstdlib>\n",
    "#include <ctime>\n",
    "\n",
    "// CUDA headers\n",
    "#include <cuda_runtime.h>\n",
    "#include <cublas_v2.h>\n",
    "#include <cudnn.h>\n",
    "\n",
    "// Some constants, for demonstration\n",
    "#define CHECK_CUDA_ERR(x)  do { if((x) != cudaSuccess) { \\\n",
    "                                fprintf(stderr,\"Error at %s:%d - %s\\n\",__FILE__,__LINE__,cudaGetErrorString(x)); \\\n",
    "                                exit(EXIT_FAILURE);}} while(0)\n",
    "\n",
    "#define CHECK_CUBLAS_ERR(x) do { if((x) != CUBLAS_STATUS_SUCCESS) { \\\n",
    "                                  fprintf(stderr,\"CUBLAS Error at %s:%d\\n\",__FILE__,__LINE__); \\\n",
    "                                  exit(EXIT_FAILURE);}} while(0)\n",
    "\n",
    "#define CHECK_CUDNN_ERR(x) do { cudnnStatus_t status_ = (x); \\\n",
    "                                if (status_ != CUDNN_STATUS_SUCCESS) { \\\n",
    "                                  fprintf(stderr, \"cuDNN Error: %s at %s:%d\\n\", \\\n",
    "                                          cudnnGetErrorString(status_), __FILE__, __LINE__); \\\n",
    "                                  exit(EXIT_FAILURE);}} while(0)\n",
    "\n",
    "//---------------------------------------------\n",
    "// Utility functions\n",
    "//---------------------------------------------\n",
    "static inline float randomFloat(float low = -1.0f, float high = 1.0f)\n",
    "{\n",
    "    float r = static_cast<float>(rand()) / static_cast<float>(RAND_MAX);\n",
    "    return low + r * (high - low);\n",
    "}\n",
    "\n",
    "__global__ void fillArrayKernel(float* arr, int N, float value)\n",
    "{\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(idx < N) arr[idx] = value;\n",
    "}\n",
    "\n",
    "__global__ void addArraysKernel(const float* a, const float* b, float* c, int N)\n",
    "{\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(idx < N) c[idx] = a[idx] + b[idx];\n",
    "}\n",
    "\n",
    "__global__ void reluKernel(float* data, int N)\n",
    "{\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(idx < N) data[idx] = fmaxf(0.0f, data[idx]);\n",
    "}\n",
    "\n",
    "__global__ void reluBackwardKernel(const float* input, const float* gradOutput, float* gradInput, int N)\n",
    "{\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(idx < N)\n",
    "        gradInput[idx] = (input[idx] > 0.0f) ? gradOutput[idx] : 0.0f;\n",
    "}\n",
    "\n",
    "__global__ void squareKernel(float* data, int N)\n",
    "{\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if(idx < N)\n",
    "    {\n",
    "        float val = data[idx];\n",
    "        data[idx] = 0.5f * val * val; // 1/2 * (val^2)\n",
    "    }\n",
    "}\n",
    "\n",
    "// Wrapper for fill kernel\n",
    "void gpuFillArray(float* d_arr, int N, float value)\n",
    "{\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    fillArrayKernel<<<blocks, threads>>>(d_arr, N, value);\n",
    "    CHECK_CUDA_ERR(cudaDeviceSynchronize());\n",
    "}\n",
    "\n",
    "// Wrapper for add kernel\n",
    "void gpuAddArrays(const float* d_a, const float* d_b, float* d_c, int N)\n",
    "{\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    addArraysKernel<<<blocks, threads>>>(d_a, d_b, d_c, N);\n",
    "    CHECK_CUDA_ERR(cudaDeviceSynchronize());\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// cuBLAS matrix-multiply: C = A * B\n",
    "// A: (M x K), B: (K x N), C: (M x N)\n",
    "//---------------------------------------------\n",
    "void matMulCuBLAS(cublasHandle_t handle,\n",
    "                  const float* d_A, const float* d_B, float* d_C,\n",
    "                  int M, int N, int K)\n",
    "{\n",
    "    const float alpha = 1.0f;\n",
    "    const float beta  = 0.0f;\n",
    "    CHECK_CUBLAS_ERR(\n",
    "        cublasSgemm(handle,\n",
    "                    CUBLAS_OP_N, CUBLAS_OP_N,\n",
    "                    M, N, K,\n",
    "                    &alpha,\n",
    "                    d_A, M,\n",
    "                    d_B, K,\n",
    "                    &beta,\n",
    "                    d_C, M)\n",
    "    );\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// Fully connected: y = W*x + b\n",
    "// W: (outDim x inDim), x: (inDim x 1)\n",
    "//---------------------------------------------\n",
    "void fullyConnectedLayer(cublasHandle_t handle,\n",
    "                         const float* d_W,\n",
    "                         /*const float* d_b,*/ // b addition is separate\n",
    "                         const float* d_x,\n",
    "                         float* d_y,\n",
    "                         int inDim,\n",
    "                         int outDim)\n",
    "{\n",
    "    // y = W*x (we'll add bias with a separate kernel or approach)\n",
    "    matMulCuBLAS(handle, d_W, d_x, d_y, outDim, 1, inDim);\n",
    "}\n",
    "\n",
    "// Add bias (per-element)\n",
    "__global__ void addBiasKernel(float* d_y, const float* d_b, int outDim)\n",
    "{\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if(idx < outDim)\n",
    "        d_y[idx] += d_b[idx];\n",
    "}\n",
    "\n",
    "void fullyConnectedLayerAddBias(const float* d_b, float* d_y, int outDim)\n",
    "{\n",
    "    int threads = 256;\n",
    "    int blocks = (outDim + threads - 1) / threads;\n",
    "    addBiasKernel<<<blocks, threads>>>(d_y, d_b, outDim);\n",
    "    CHECK_CUDA_ERR(cudaDeviceSynchronize());\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// Backprop for fully connected layer\n",
    "// gradOut: gradient wrt output (outDim x 1)\n",
    "// X: input (inDim x 1)\n",
    "// W: (outDim x inDim)\n",
    "//---------------------------------------------\n",
    "void backpropFullyConnected(cublasHandle_t handle,\n",
    "                            const float* d_gradOut,\n",
    "                            const float* d_X,\n",
    "                            const float* d_W,\n",
    "                            float* d_gradW,\n",
    "                            float* d_gradB,\n",
    "                            float* d_gradX,\n",
    "                            int inDim, int outDim)\n",
    "{\n",
    "    // gradW = gradOut * X^T => (outDim x 1)*(1 x inDim) => (outDim x inDim)\n",
    "    {\n",
    "        const float alpha = 1.0f;\n",
    "        const float beta  = 0.0f;\n",
    "        CHECK_CUBLAS_ERR(\n",
    "            cublasSgemm(handle,\n",
    "                        CUBLAS_OP_N, CUBLAS_OP_T,\n",
    "                        outDim, inDim, 1,\n",
    "                        &alpha,\n",
    "                        d_gradOut, outDim,\n",
    "                        d_X, inDim,\n",
    "                        &beta,\n",
    "                        d_gradW, outDim)\n",
    "        );\n",
    "    }\n",
    "\n",
    "    // gradB = gradOut (one value per output neuron in this single-sample case)\n",
    "    CHECK_CUDA_ERR(cudaMemcpy(d_gradB, d_gradOut, outDim*sizeof(float), cudaMemcpyDeviceToDevice));\n",
    "\n",
    "    // gradX = W^T * gradOut => (inDim x outDim)*(outDim x 1) => (inDim x 1)\n",
    "    {\n",
    "        const float alpha = 1.0f;\n",
    "        const float beta  = 0.0f;\n",
    "        CHECK_CUBLAS_ERR(\n",
    "            cublasSgemm(handle,\n",
    "                        CUBLAS_OP_T, CUBLAS_OP_N,\n",
    "                        inDim, 1, outDim,\n",
    "                        &alpha,\n",
    "                        d_W, outDim,\n",
    "                        d_gradOut, outDim,\n",
    "                        &beta,\n",
    "                        d_gradX, inDim)\n",
    "        );\n",
    "    }\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// Extra cuDNN demos: Convolution, ReLU, Pooling, Softmax\n",
    "//---------------------------------------------\n",
    "void cudnnConvolutionExample(cudnnHandle_t cudnn)\n",
    "{\n",
    "    std::cout << \"[INFO] Running a sample cuDNN Convolution...\\n\";\n",
    "\n",
    "    cudnnTensorDescriptor_t inDesc, outDesc;\n",
    "    cudnnFilterDescriptor_t filtDesc;\n",
    "    cudnnConvolutionDescriptor_t convDesc;\n",
    "\n",
    "    CHECK_CUDNN_ERR( cudnnCreateTensorDescriptor(&inDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnCreateTensorDescriptor(&outDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnCreateFilterDescriptor(&filtDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnCreateConvolutionDescriptor(&convDesc) );\n",
    "\n",
    "    // For a 28x28 single-channel example\n",
    "    CHECK_CUDNN_ERR( cudnnSetTensor4dDescriptor(inDesc, CUDNN_TENSOR_NCHW,\n",
    "                                                CUDNN_DATA_FLOAT,\n",
    "                                                1, 1, 28, 28) );\n",
    "\n",
    "    CHECK_CUDNN_ERR( cudnnSetTensor4dDescriptor(outDesc, CUDNN_TENSOR_NCHW,\n",
    "                                                CUDNN_DATA_FLOAT,\n",
    "                                                1, 1, 24, 24) );\n",
    "\n",
    "    CHECK_CUDNN_ERR( cudnnSetFilter4dDescriptor(filtDesc,\n",
    "                                                CUDNN_DATA_FLOAT,\n",
    "                                                CUDNN_TENSOR_NCHW,\n",
    "                                                1, 1, 5, 5) );\n",
    "\n",
    "    CHECK_CUDNN_ERR( cudnnSetConvolution2dDescriptor(convDesc,\n",
    "                                                     0, 0,\n",
    "                                                     1, 1,\n",
    "                                                     1, 1,\n",
    "                                                     CUDNN_CROSS_CORRELATION,\n",
    "                                                     CUDNN_DATA_FLOAT) );\n",
    "\n",
    "    // We'll pick a known forward algo\n",
    "    cudnnConvolutionFwdAlgo_t algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;\n",
    "\n",
    "    size_t workspaceBytes = 0;\n",
    "    CHECK_CUDNN_ERR(\n",
    "        cudnnGetConvolutionForwardWorkspaceSize(\n",
    "            cudnn, inDesc, filtDesc, convDesc, outDesc, algo, &workspaceBytes)\n",
    "    );\n",
    "\n",
    "    void* d_workspace = nullptr;\n",
    "    if (workspaceBytes > 0)\n",
    "        CHECK_CUDA_ERR( cudaMalloc(&d_workspace, workspaceBytes) );\n",
    "\n",
    "    float *d_input = nullptr, *d_filter = nullptr, *d_output = nullptr;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_input,  1*1*28*28*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_filter, 1*1*5*5*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_output, 1*1*24*24*sizeof(float)) );\n",
    "\n",
    "    // fill input/filter with some constants\n",
    "    gpuFillArray(d_input, 1*1*28*28, 0.1f);\n",
    "    gpuFillArray(d_filter, 1*1*5*5,  0.2f);\n",
    "\n",
    "    const float alpha = 1.0f, beta = 0.0f;\n",
    "    CHECK_CUDNN_ERR(\n",
    "        cudnnConvolutionForward(cudnn,\n",
    "                                &alpha,\n",
    "                                inDesc, d_input,\n",
    "                                filtDesc, d_filter,\n",
    "                                convDesc, algo,\n",
    "                                d_workspace, workspaceBytes,\n",
    "                                &beta,\n",
    "                                outDesc, d_output)\n",
    "    );\n",
    "\n",
    "    // Cleanup\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyConvolutionDescriptor(convDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyFilterDescriptor(filtDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyTensorDescriptor(inDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyTensorDescriptor(outDesc) );\n",
    "    if(d_workspace) cudaFree(d_workspace);\n",
    "\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_filter);\n",
    "    cudaFree(d_output);\n",
    "\n",
    "    std::cout << \"[INFO] cuDNN Convolution example complete.\\n\";\n",
    "}\n",
    "\n",
    "void cudnnReluExample(cudnnHandle_t cudnn)\n",
    "{\n",
    "    std::cout << \"[INFO] Running a sample cuDNN ReLU...\\n\";\n",
    "\n",
    "    cudnnTensorDescriptor_t desc;\n",
    "    cudnnActivationDescriptor_t actDesc;\n",
    "    CHECK_CUDNN_ERR( cudnnCreateTensorDescriptor(&desc) );\n",
    "    CHECK_CUDNN_ERR( cudnnCreateActivationDescriptor(&actDesc) );\n",
    "\n",
    "    CHECK_CUDNN_ERR( cudnnSetTensor4dDescriptor(desc,\n",
    "                                                CUDNN_TENSOR_NCHW,\n",
    "                                                CUDNN_DATA_FLOAT,\n",
    "                                                1, 10, 1, 1) );\n",
    "\n",
    "    CHECK_CUDNN_ERR( cudnnSetActivationDescriptor(actDesc,\n",
    "                                                  CUDNN_ACTIVATION_RELU,\n",
    "                                                  CUDNN_PROPAGATE_NAN,\n",
    "                                                  0.0) );\n",
    "\n",
    "    float *d_input = nullptr, *d_output = nullptr;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_input,  10*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_output, 10*sizeof(float)) );\n",
    "\n",
    "    // Fill with negative to see ReLU effect\n",
    "    gpuFillArray(d_input, 10, -0.5f);\n",
    "\n",
    "    float alpha = 1.0f, beta = 0.0f;\n",
    "    CHECK_CUDNN_ERR(\n",
    "        cudnnActivationForward(cudnn,\n",
    "                               actDesc,\n",
    "                               &alpha,\n",
    "                               desc, d_input,\n",
    "                               &beta,\n",
    "                               desc, d_output)\n",
    "    );\n",
    "\n",
    "    // Cleanup\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyActivationDescriptor(actDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyTensorDescriptor(desc) );\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "\n",
    "    std::cout << \"[INFO] cuDNN ReLU example complete.\\n\";\n",
    "}\n",
    "\n",
    "void cudnnPoolingExample(cudnnHandle_t cudnn)\n",
    "{\n",
    "    std::cout << \"[INFO] Running a sample cuDNN pooling (Max Pool)...\\n\";\n",
    "\n",
    "    cudnnTensorDescriptor_t inDesc, outDesc;\n",
    "    cudnnPoolingDescriptor_t poolDesc;\n",
    "    CHECK_CUDNN_ERR( cudnnCreateTensorDescriptor(&inDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnCreateTensorDescriptor(&outDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnCreatePoolingDescriptor(&poolDesc) );\n",
    "\n",
    "    // 1x1x6x6 input\n",
    "    CHECK_CUDNN_ERR(\n",
    "        cudnnSetTensor4dDescriptor(inDesc, CUDNN_TENSOR_NCHW,\n",
    "                                   CUDNN_DATA_FLOAT, 1, 1, 6, 6) );\n",
    "\n",
    "    // 2x2 kernel, stride 2 => output 1x1x3x3\n",
    "    CHECK_CUDNN_ERR(\n",
    "        cudnnSetTensor4dDescriptor(outDesc, CUDNN_TENSOR_NCHW,\n",
    "                                   CUDNN_DATA_FLOAT, 1, 1, 3, 3) );\n",
    "\n",
    "    CHECK_CUDNN_ERR(\n",
    "        cudnnSetPooling2dDescriptor(poolDesc,\n",
    "                                    CUDNN_POOLING_MAX,\n",
    "                                    CUDNN_PROPAGATE_NAN,\n",
    "                                    2, 2,  // window\n",
    "                                    0, 0,  // pad\n",
    "                                    2, 2)  // stride\n",
    "    );\n",
    "\n",
    "    float *d_input = nullptr, *d_output = nullptr;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_input,  6*6*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_output, 3*3*sizeof(float)) );\n",
    "\n",
    "    // Fill input with random data\n",
    "    std::vector<float> h_in(36);\n",
    "    for (int i = 0; i < 36; i++){\n",
    "        h_in[i] = (float)(rand() % 100);\n",
    "    }\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(d_input, h_in.data(), 36*sizeof(float),\n",
    "                               cudaMemcpyHostToDevice) );\n",
    "\n",
    "    float alpha = 1.0f, beta = 0.0f;\n",
    "    CHECK_CUDNN_ERR(\n",
    "        cudnnPoolingForward(cudnn,\n",
    "                            poolDesc,\n",
    "                            &alpha,\n",
    "                            inDesc, d_input,\n",
    "                            &beta,\n",
    "                            outDesc, d_output)\n",
    "    );\n",
    "\n",
    "    // Download result\n",
    "    std::vector<float> h_out(9);\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(h_out.data(), d_output, 9*sizeof(float),\n",
    "                               cudaMemcpyDeviceToHost) );\n",
    "\n",
    "    std::cout << \"[INFO] pooled output (3x3):\\n\";\n",
    "    for(int i=0; i<9; i++){\n",
    "        std::cout << std::setw(5) << h_out[i]\n",
    "                  << ((i%3==2) ? \"\\n\" : \" \");\n",
    "    }\n",
    "\n",
    "    // Cleanup\n",
    "    CHECK_CUDA_ERR( cudaFree(d_input) );\n",
    "    CHECK_CUDA_ERR( cudaFree(d_output) );\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyPoolingDescriptor(poolDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyTensorDescriptor(inDesc) );\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyTensorDescriptor(outDesc) );\n",
    "\n",
    "    std::cout << \"[INFO] cuDNN pooling example complete.\\n\";\n",
    "}\n",
    "\n",
    "void cudnnSoftmaxExample(cudnnHandle_t cudnn)\n",
    "{\n",
    "    std::cout << \"[INFO] Running a sample cuDNN Softmax...\\n\";\n",
    "    cudnnTensorDescriptor_t desc;\n",
    "    CHECK_CUDNN_ERR( cudnnCreateTensorDescriptor(&desc) );\n",
    "\n",
    "    CHECK_CUDNN_ERR(\n",
    "        cudnnSetTensor4dDescriptor(desc,\n",
    "                                   CUDNN_TENSOR_NCHW,\n",
    "                                   CUDNN_DATA_FLOAT,\n",
    "                                   1, 5, 1, 1) );\n",
    "\n",
    "    float *d_input = nullptr, *d_output = nullptr;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_input,  5*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_output, 5*sizeof(float)) );\n",
    "\n",
    "    // Fill input with random values\n",
    "    std::vector<float> h_in(5);\n",
    "    for(int i=0; i<5; i++){\n",
    "        h_in[i] = randomFloat(-2.0f, 2.0f);\n",
    "    }\n",
    "\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(d_input, h_in.data(),\n",
    "                               5*sizeof(float),\n",
    "                               cudaMemcpyHostToDevice) );\n",
    "\n",
    "    float alpha = 1.0f, beta = 0.0f;\n",
    "    CHECK_CUDNN_ERR(\n",
    "        cudnnSoftmaxForward(cudnn,\n",
    "                            CUDNN_SOFTMAX_ACCURATE,  // or CUDNN_SOFTMAX_FAST\n",
    "                            CUDNN_SOFTMAX_MODE_INSTANCE,\n",
    "                            &alpha,\n",
    "                            desc, d_input,\n",
    "                            &beta,\n",
    "                            desc, d_output)\n",
    "    );\n",
    "\n",
    "    // Retrieve and print output\n",
    "    std::vector<float> h_out(5);\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(h_out.data(), d_output, 5*sizeof(float),\n",
    "                               cudaMemcpyDeviceToHost) );\n",
    "\n",
    "    std::cout << \"[INFO] softmax input -> output:\\n\";\n",
    "    for(int i=0; i<5; i++){\n",
    "        std::cout << \"  \" << h_in[i] << \" -> \" << h_out[i] << \"\\n\";\n",
    "    }\n",
    "\n",
    "    // Cleanup\n",
    "    CHECK_CUDA_ERR( cudaFree(d_input) );\n",
    "    CHECK_CUDA_ERR( cudaFree(d_output) );\n",
    "    CHECK_CUDNN_ERR( cudnnDestroyTensorDescriptor(desc) );\n",
    "\n",
    "    std::cout << \"[INFO] cuDNN softmax example complete.\\n\";\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// Stub for NPP image rotation\n",
    "//---------------------------------------------\n",
    "void nppImageRotationExample(const std::string& filename)\n",
    "{\n",
    "    // Stub only. No actual NPP calls here.\n",
    "    std::cout << \"[INFO] (Stub) NPP image rotation of \" << filename << \"\\n\";\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// CPU helper for random init\n",
    "//---------------------------------------------\n",
    "void cpuRandomInit(float* d_arr, int N, float low=-1.0f, float high=1.0f)\n",
    "{\n",
    "    std::vector<float> hostVec(N);\n",
    "    for(int i=0; i<N; i++){\n",
    "        hostVec[i] = randomFloat(low, high);\n",
    "    }\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(d_arr, hostVec.data(),\n",
    "                               N*sizeof(float),\n",
    "                               cudaMemcpyHostToDevice) );\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// Simple NN training (2-layer MLP) with actual\n",
    "// gradient updates so the MSE won't stay at 0.\n",
    "//---------------------------------------------\n",
    "void simpleNeuralNetworkTraining(cublasHandle_t cublas,\n",
    "                                 int inputSize,\n",
    "                                 int hiddenSize,\n",
    "                                 int outputSize,\n",
    "                                 int iterations = 5)\n",
    "{\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    std::cout << \"[INFO] starting simple NN training (\"\n",
    "              << iterations << \" iterations)...\\n\";\n",
    "\n",
    "    // 1) Allocate weights & biases\n",
    "    float *d_W1, *d_b1, *d_W2, *d_b2;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_W1, hiddenSize * inputSize * sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_b1, hiddenSize * sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_W2, outputSize * hiddenSize * sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_b2, outputSize * sizeof(float)) );\n",
    "\n",
    "    // 2) Initialize them in [-0.5, 0.5], for example\n",
    "    cpuRandomInit(d_W1, hiddenSize*inputSize, -0.5f, 0.5f);\n",
    "    cpuRandomInit(d_b1, hiddenSize, -0.5f, 0.5f);\n",
    "    cpuRandomInit(d_W2, outputSize*hiddenSize, -0.5f, 0.5f);\n",
    "    cpuRandomInit(d_b2, outputSize, -0.5f, 0.5f);\n",
    "\n",
    "    // 3) Allocate input & ground truth (single sample for demo)\n",
    "    float *d_x, *d_yGT;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_x, inputSize * sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_yGT, outputSize * sizeof(float)) );\n",
    "\n",
    "    // Input in [0,1]\n",
    "    cpuRandomInit(d_x, inputSize, 0.0f, 1.0f);\n",
    "\n",
    "    // Ground truth: all zeros except 1 for the first dimension\n",
    "    gpuFillArray(d_yGT, outputSize, 0.0f);\n",
    "    float oneVal = 1.0f;\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(d_yGT, &oneVal,\n",
    "                               sizeof(float),\n",
    "                               cudaMemcpyHostToDevice) );\n",
    "\n",
    "    // Prepare device arrays for intermediate results\n",
    "    float *d_h1, *d_h2;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_h1, hiddenSize*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_h2, outputSize*sizeof(float)) );\n",
    "\n",
    "    float *d_lossVec;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_lossVec, outputSize*sizeof(float)) );\n",
    "\n",
    "    float *d_gradOut2;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_gradOut2, outputSize*sizeof(float)) );\n",
    "\n",
    "    float *d_gradW2, *d_gradB2, *d_gradH1;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_gradW2, outputSize*hiddenSize*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_gradB2, outputSize*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_gradH1, hiddenSize*sizeof(float)) );\n",
    "\n",
    "    float *d_gradW1, *d_gradB1, *d_gradX;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_gradW1, hiddenSize*inputSize*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_gradB1, hiddenSize*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_gradX, inputSize*sizeof(float)) );\n",
    "\n",
    "    // Learning rate\n",
    "    const float learningRate = 0.01f;\n",
    "    const float negLR = -learningRate;\n",
    "\n",
    "    // 4) Training loop\n",
    "    for(int iter=0; iter<iterations; iter++)\n",
    "    {\n",
    "        //---------------------------------\n",
    "        // Forward pass: fc1 -> add bias -> ReLU -> fc2 -> add bias\n",
    "        //---------------------------------\n",
    "        // FC1\n",
    "        fullyConnectedLayer(cublas, d_W1, d_x, d_h1, inputSize, hiddenSize);\n",
    "        fullyConnectedLayerAddBias(d_b1, d_h1, hiddenSize);\n",
    "\n",
    "        // ReLU\n",
    "        {\n",
    "            int threads = 256;\n",
    "            int blocks = (hiddenSize + threads - 1) / threads;\n",
    "            reluKernel<<<blocks, threads>>>(d_h1, hiddenSize);\n",
    "            CHECK_CUDA_ERR(cudaDeviceSynchronize());\n",
    "        }\n",
    "\n",
    "        // FC2\n",
    "        fullyConnectedLayer(cublas, d_W2, d_h1, d_h2, hiddenSize, outputSize);\n",
    "        fullyConnectedLayerAddBias(d_b2, d_h2, outputSize);\n",
    "\n",
    "        //---------------------------------\n",
    "        // Compute MSE Loss = 0.5 * sum((h2 - yGT)^2)\n",
    "        // We'll do (h2 - yGT) in d_lossVec, then square each element * 0.5\n",
    "        //---------------------------------\n",
    "        // Step 1: d_lossVec = h2\n",
    "        CHECK_CUBLAS_ERR( cublasScopy(cublas, outputSize, d_h2, 1, d_lossVec, 1) );\n",
    "        // Step 2: d_lossVec -= yGT\n",
    "        const float alphaNegOne = -1.0f;\n",
    "        CHECK_CUBLAS_ERR( cublasSaxpy(cublas, outputSize, &alphaNegOne, d_yGT, 1, d_lossVec, 1) );\n",
    "        // Step 3: square each element => 0.5 * val^2\n",
    "        {\n",
    "            int threads = 256;\n",
    "            int blocks = (outputSize + threads - 1) / threads;\n",
    "            squareKernel<<<blocks, threads>>>(d_lossVec, outputSize);\n",
    "            CHECK_CUDA_ERR(cudaDeviceSynchronize());\n",
    "        }\n",
    "        // Sum on CPU for printing\n",
    "        std::vector<float> h_lossVec(outputSize);\n",
    "        CHECK_CUDA_ERR( cudaMemcpy(h_lossVec.data(), d_lossVec, outputSize*sizeof(float),\n",
    "                                   cudaMemcpyDeviceToHost) );\n",
    "        float lossSum = 0.f;\n",
    "        for(float v : h_lossVec) lossSum += v;\n",
    "\n",
    "        //---------------------------------\n",
    "        // Backprop\n",
    "        // gradOut2 = (h2 - yGT)\n",
    "        //---------------------------------\n",
    "        CHECK_CUBLAS_ERR( cublasScopy(cublas, outputSize, d_h2, 1, d_gradOut2, 1) );\n",
    "        CHECK_CUBLAS_ERR( cublasSaxpy(cublas, outputSize, &alphaNegOne, d_yGT, 1, d_gradOut2, 1) );\n",
    "\n",
    "        // backprop fc2\n",
    "        backpropFullyConnected(cublas, d_gradOut2, d_h1, d_W2,\n",
    "                               d_gradW2, d_gradB2, d_gradH1,\n",
    "                               hiddenSize, outputSize);\n",
    "\n",
    "        // backprop ReLU\n",
    "        {\n",
    "            int threads = 256;\n",
    "            int blocks = (hiddenSize + threads - 1) / threads;\n",
    "            reluBackwardKernel<<<blocks, threads>>>(d_h1, d_gradH1, d_gradH1, hiddenSize);\n",
    "            CHECK_CUDA_ERR(cudaDeviceSynchronize());\n",
    "        }\n",
    "\n",
    "        // backprop fc1\n",
    "        backpropFullyConnected(cublas, d_gradH1, d_x, d_W1,\n",
    "                               d_gradW1, d_gradB1, d_gradX,\n",
    "                               inputSize, hiddenSize);\n",
    "\n",
    "        //---------------------------------\n",
    "        // Gradient descent update\n",
    "        // W2 -= LR * d_gradW2, etc.\n",
    "        //---------------------------------\n",
    "        CHECK_CUBLAS_ERR( cublasSaxpy(cublas, outputSize*hiddenSize,\n",
    "                                       &negLR, d_gradW2, 1, d_W2, 1) );\n",
    "        CHECK_CUBLAS_ERR( cublasSaxpy(cublas, outputSize,\n",
    "                                       &negLR, d_gradB2, 1, d_b2, 1) );\n",
    "        CHECK_CUBLAS_ERR( cublasSaxpy(cublas, hiddenSize*inputSize,\n",
    "                                       &negLR, d_gradW1, 1, d_W1, 1) );\n",
    "        CHECK_CUBLAS_ERR( cublasSaxpy(cublas, hiddenSize,\n",
    "                                       &negLR, d_gradB1, 1, d_b1, 1) );\n",
    "\n",
    "        //---------------------------------\n",
    "        // Print iteration info\n",
    "        //---------------------------------\n",
    "        std::cout << \"  [Iteration \" << (iter+1)\n",
    "                  << \"] MSE Loss = \" << lossSum << \"\\n\";\n",
    "    }\n",
    "\n",
    "    // Cleanup\n",
    "    cudaFree(d_W1);\n",
    "    cudaFree(d_b1);\n",
    "    cudaFree(d_W2);\n",
    "    cudaFree(d_b2);\n",
    "    cudaFree(d_x);\n",
    "    cudaFree(d_yGT);\n",
    "    cudaFree(d_h1);\n",
    "    cudaFree(d_h2);\n",
    "    cudaFree(d_lossVec);\n",
    "    cudaFree(d_gradOut2);\n",
    "    cudaFree(d_gradW2);\n",
    "    cudaFree(d_gradB2);\n",
    "    cudaFree(d_gradH1);\n",
    "    cudaFree(d_gradW1);\n",
    "    cudaFree(d_gradB1);\n",
    "    cudaFree(d_gradX);\n",
    "\n",
    "    std::cout << \"[INFO] finished simple NN training example.\\n\";\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// Additional example: Dot product (cublasSdot)\n",
    "//---------------------------------------------\n",
    "void cublasDotProductExample(cublasHandle_t handle)\n",
    "{\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    std::cout << \"[INFO] Running a cuBLAS dot product example...\\n\";\n",
    "    int N = 10;\n",
    "    float *d_a, *d_b;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_a, N*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_b, N*sizeof(float)) );\n",
    "\n",
    "    // Fill with some values\n",
    "    std::vector<float> h_a(N), h_b(N);\n",
    "    for(int i=0; i<N; i++){\n",
    "        h_a[i] = float(i+1); // 1,2,3,...\n",
    "        h_b[i] = 2.0f;       // all 2\n",
    "    }\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(d_a, h_a.data(), N*sizeof(float), cudaMemcpyHostToDevice) );\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(d_b, h_b.data(), N*sizeof(float), cudaMemcpyHostToDevice) );\n",
    "\n",
    "    float result = 0.0f;\n",
    "    CHECK_CUBLAS_ERR( cublasSdot(handle, N, d_a, 1, d_b, 1, &result) );\n",
    "\n",
    "    std::cout << \"  Dot product of [1..10] and [2..2] = \" << result\n",
    "              << \" (expected 110)\\n\";\n",
    "\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    std::cout << \"[INFO] cuBLAS dot product example complete.\\n\";\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// Additional example: Matrix-Vector multiply (cublasSgemv)\n",
    "//---------------------------------------------\n",
    "void cublasMatVecExample(cublasHandle_t handle)\n",
    "{\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    std::cout << \"[INFO] Running a cuBLAS matrix-vector example (SGEMV)...\\n\";\n",
    "\n",
    "    // Let A be 3x3, x be 3x1 => y = A*x => 3x1\n",
    "    float A[9] = {1.f,2.f,3.f,\n",
    "                  4.f,5.f,6.f,\n",
    "                  7.f,8.f,9.f};\n",
    "    float x[3] = {1.f, 2.f, 3.f};\n",
    "    float *d_A, *d_x, *d_y;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_A, 9*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_x, 3*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_y, 3*sizeof(float)) );\n",
    "\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(d_A, A, 9*sizeof(float), cudaMemcpyHostToDevice) );\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(d_x, x, 3*sizeof(float), cudaMemcpyHostToDevice) );\n",
    "\n",
    "    // Zero out d_y\n",
    "    gpuFillArray(d_y, 3, 0.0f);\n",
    "\n",
    "    float alpha = 1.f, beta = 0.f;\n",
    "    CHECK_CUBLAS_ERR(\n",
    "        cublasSgemv(handle, CUBLAS_OP_N,\n",
    "                    3, 3,\n",
    "                    &alpha,\n",
    "                    d_A, 3,\n",
    "                    d_x, 1,\n",
    "                    &beta,\n",
    "                    d_y, 1)\n",
    "    );\n",
    "\n",
    "    // Retrieve result\n",
    "    float y[3];\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(y, d_y, 3*sizeof(float), cudaMemcpyDeviceToHost) );\n",
    "    std::cout << \"  [1 2 3; 4 5 6; 7 8 9] * [1; 2; 3] = [\"\n",
    "              << y[0] << \" \" << y[1] << \" \" << y[2] << \"]^T\\n\";\n",
    "    // should be [14 32 50]^T\n",
    "\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_x);\n",
    "    cudaFree(d_y);\n",
    "\n",
    "    std::cout << \"[INFO] cuBLAS SGEMV example complete.\\n\";\n",
    "}\n",
    "\n",
    "//---------------------------------------------\n",
    "// MAIN\n",
    "//---------------------------------------------\n",
    "int main(int argc, char** argv)\n",
    "{\n",
    "    srand((unsigned)time(nullptr));\n",
    "    CHECK_CUDA_ERR( cudaSetDevice(0) );\n",
    "\n",
    "    // Create cuBLAS handle\n",
    "    cublasHandle_t cublas;\n",
    "    CHECK_CUBLAS_ERR( cublasCreate(&cublas) );\n",
    "\n",
    "    // Create cuDNN handle\n",
    "    cudnnHandle_t cudnn;\n",
    "    CHECK_CUDNN_ERR( cudnnCreate(&cudnn) );\n",
    "\n",
    "    // 1) Basic array ops\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    std::cout << \"[INFO] Basic array ops demo\\n\";\n",
    "    int N = 1000;\n",
    "    float *d_a, *d_b, *d_c;\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_a, N*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_b, N*sizeof(float)) );\n",
    "    CHECK_CUDA_ERR( cudaMalloc(&d_c, N*sizeof(float)) );\n",
    "\n",
    "    gpuFillArray(d_a, N, 1.0f);\n",
    "    gpuFillArray(d_b, N, 2.0f);\n",
    "    gpuAddArrays(d_a, d_b, d_c, N);\n",
    "\n",
    "    // Download & check\n",
    "    std::vector<float> h_c(N);\n",
    "    CHECK_CUDA_ERR( cudaMemcpy(h_c.data(), d_c, N*sizeof(float), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "    float sumCheck = 0.0f;\n",
    "    for(int i=0; i<N; i++){\n",
    "        sumCheck += h_c[i];\n",
    "    }\n",
    "    std::cout << \"[INFO] Sum of c after add: \" << sumCheck\n",
    "              << \" (expected ~3000 if N=1000)\\n\";\n",
    "\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "\n",
    "    // 2) Dot product with cuBLAS\n",
    "    cublasDotProductExample(cublas);\n",
    "\n",
    "    // 3) Matrix-vector multiply with cuBLAS\n",
    "    cublasMatVecExample(cublas);\n",
    "\n",
    "    // 4) cuDNN Convolution\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    cudnnConvolutionExample(cudnn);\n",
    "\n",
    "    // 5) cuDNN ReLU\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    cudnnReluExample(cudnn);\n",
    "\n",
    "    // 6) cuDNN Pooling\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    cudnnPoolingExample(cudnn);\n",
    "\n",
    "    // 7) cuDNN Softmax\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    cudnnSoftmaxExample(cudnn);\n",
    "\n",
    "    // 8) NPP image rotation (stub)\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    nppImageRotationExample(\"input.png\");\n",
    "\n",
    "    // 9) Simple NN training with multiple iterations + gradient update\n",
    "    simpleNeuralNetworkTraining(cublas, /*inputSize=*/128,\n",
    "                                           /*hiddenSize=*/64,\n",
    "                                           /*outputSize=*/10,\n",
    "                                           /*iterations=*/5);\n",
    "\n",
    "    // Cleanup handles\n",
    "    CHECK_CUBLAS_ERR( cublasDestroy(cublas) );\n",
    "    CHECK_CUDNN_ERR( cudnnDestroy(cudnn) );\n",
    "\n",
    "    std::cout << \"----------------------------------\\n\";\n",
    "    std::cout << \"[INFO] Program finished successfully.\\n\";\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpOy-qQBxmsJ",
    "outputId": "ad68cef8-d398-4ff6-b334-1edbbb91f122"
   },
   "outputs": [],
   "source": [
    "# 1) Write the file (the code above) in a notebook cell with %%writefile code_cuda.cu\n",
    "# 2) Compile:\n",
    "!nvcc code_cuda.cu -o code_cuda -lcublas -lcudnn\n",
    "# 3) Run:\n",
    "!./code_cuda\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
